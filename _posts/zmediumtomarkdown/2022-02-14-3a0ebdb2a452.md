---
title: "Machine Learning hasn’t Learnt Enough about Ethics"
author: "Mx. Taiss"
date: 2022-02-14T22:31:23.826+0000
last_modified_at: 2022-02-14T22:31:23.826+0000
categories: [""]
tags: ["ethics-by-design","ethics-in-tech","machine-learning","artificial-intelligence","design-for-good"]
description: "Seminary College can be a weird place."
image:
  path: /assets/3a0ebdb2a452/0*49bxF11TL-S4D7zV
render_with_liquid: false
---

### Machine Learning hasn’t Learnt Enough about Ethics


![](/assets/3a0ebdb2a452/0*49bxF11TL-S4D7zV)


Seminary College can be a weird place\.

It feels like a weird mashup of a doomsday bunker, a University Bar and Catholic Hogwarts\. The characters you’ll meet seem like they’re creations from an 80s inspired 90s sitcom — with personalities so extreme that you’ll be amazed that people like this even exist\.

But it wasn’t for me\.

If I noticed one thing about leaving the seminary, it was a large increase in free time on Sunday morning when I used to attend mass\. I also became free on Wednesday evenings when I would volunteer with the Church, and on weekends I would spend with friends from the community\. Leaving a religious tradition was more than just a change in my religious identity; it was a withdrawal from an active community\.

Don’t get me wrong, there are a million and one ways to organise a group of people, but religious institutions seem to do it shockingly well\. Think about it\. They provide you with a set place and time where you come together to discuss your values, experiences, and aspirations in life\. You get the opportunity to connect with people who have a similar vision of the world, and your individual role in it\. Then, if they’re really good, they actually motivate you to go and do something about it\.

The most common question asked upon leaving? How can you be good without a guiding light, like God?

That triggered me onto a path of undertaking a journey of self\-study and exploration\. I saw myself as inherently good, but what made me so?

A lesson remained with me — ethics are not \(if you will excuse the pun\) written in stone\. Ethics are a living element that consciously or not, affects the way we live our lives at work or home\.

Psychological and socio\-cultural elements play a part in how we perceive ethics\. Obedience, conformity, moral disengagement, cognitive dissonance and moral amnesia have all proved to modify our behaviours\.


> _Though we see ourselves as inherently good, in certain circumstances, we are likely to misbehave\._ 



### It turns out that Ethics is a fundamentally complex and human thing\.

What does this have to do with design, technology or indeed bots?

It’s about clarity, and more specifically, transparency — of the design choices made, the data collected, the algorithms utilised — all of which are choices taken with an ethical decision by someone\.

There seems to be a sense of moral disengagement in the workforce\. For those unaware, this term from social psychology describes the process of convincing ourselves that ethical standards do not apply within this context\.

Thus, moral disengagement invokes a cognitive re\-construing or re\-framing of behaviour as being morally acceptable\. Ignoring the concern that this creates upon an individual’s psyche, or indeed the organisational culture, it has profound implications on how tech and business leaders can approach making their technology more ethical\.

With emerging technologies like machine learning, developers can now achieve much more than ever before\. But this new power can be utilised to either enhance our humanity or lead us towards dystopian futures\.
### Technology Needs Ethics Urgently

Current processes for ethics and risk assessment around uses of machine learning — or as it’s generally referred: Artificial Intelligence \(AI\) — are still relatively immature, and the urgency of a crisis highlights their limitations\.

Much work in AI ethics in recent years has focused on developing high\-level principles\. Still, these principles say nothing about what to do when principles come into conflict with one another\. For example, principles do not tell us how to balance the potential of AI to save lives \(the principle of ‘beneficence’\) against other important values such as privacy or fairness\. One common suggestion for navigating such tensions is through engagement with diverse stakeholder groups, but this may be difficult to enact with sufficient speed at times of crisis\.

Experts in ethics and risk assessment need to be involved in teams developing AI\-based solutions from the beginning, and much clearer guidelines are needed for engineers and developers to think through these issues\. An ethics by design approach should also be supplemented with more extensive foresight work, looking beyond the more obvious and immediate ethical issues, and considering a comprehensive range of longer\-term and wide\-ranging systemic impacts\.
### Business Versus Ethics

The close link between business and science can be revealed by the fact that industry partners sponsor all of the major AI conferences\.

There is considerable growth in the number of active AI startups, each supported by vast amounts of annual funding from Venture Capital firms\. Tens of thousands of AI\-related patents are registered each year\. Different industries are incorporating AI applications in a broad variety of fields, ranging from manufacturing, supply\-chain management, and service development, to marketing and risk assessment\. All in all, the global AI market comprises more than 7 billion dollars\.

Through widespread unintended consequences and externalities, this new technology can cause substantial social impacts\. It’s not just the job losses due to AI implementation\.


> _It’s easier to be harmful or to create things that annoy people than it is to create honestly helpful things\._ 





Consider the hampering of innovation and transparency through the use of trade secrets to disguise harmful or flawed AI functionalities\. Organisations conducting unmonitored forms of AI experiments on society without informed consent or oversight\. The propagation of unfair and biased algorithm use\. Privacy and safety concerns from data breaches\. Or even merely providing unsafe AI products as they are rushed to integrate and put immature AI applications on the market\.

Furthermore, criminal or black\-hat hackers can use AI to tailor cyberattacks, steal information, attack IT infrastructures, rig elections, spread misinformation \(for example through deepfakes\), use voice synthesis technologies for fraud or social engineering, or disclose personal traits that are actually secret or private via machine learning applications\.

Countless companies are eager to monetise AI in a wide variety of applications\. This strive for profitable use of machine learning systems is not primarily framed by value\- or principle\-based ethics, but obviously by economic logic\.

Engineers and developers are neither systematically educated about ethical issues, nor are they empowered, for example by organisational structures, to raise ethical concerns\. In business contexts, speed is everything and skipping ethical considerations is equivalent to the path of least resistance\. Thus, the practice of development, implementation and use of AI applications has very often little to do with the values and principles postulated by ethics\.

Ethics has no enforcement mechanisms reaching beyond voluntary and non\-binding cooperation between ethicists and individuals working in research and industry\. So, what happens is that AI research and development takes place in ‘closed\-door industry settings’\. Behind those closed doors, user consent, privacy and transparency are often overlooked in favour of frictionless functionality that supports profit\-driven business models\.

It’s not all bad, however\. Significant progress has been made in the areas of privacy and fairness\. For example, many privacy\-friendly techniques for the use of data sets and learning algorithms have been developed, using methods where AI systems’ “sight” is “darkened” via cryptography, differential or stochastic privacy\.

Nevertheless, this contradicts the observation that AI has been making such massive progress for several years precisely because of the large amounts of \(personal\) data available\. That data is collected by privacy\-invasive social media platforms, smartphone apps, as well as Internet of Things devices, with its countless sensors\.
### Ethical Standards are Not Being Met

Ethical goals are being massively underachieved\. One only has to think of the aspect of gender diversity in IT\. Even though ethical guidelines clearly demand its improvement, the state of affairs is that on average 80% of the professors at the world’s leading universities such as Stanford, Oxford, Berkeley or the ETH are male — and men make up more than 70% of applicants for AI jobs in the U\.S\.

As repeatedly demanded in various ethical guidelines, people should not be treated as mere data subjects, but as individuals\. In fact, countless examples show that computer decisions, regardless of their susceptibility to error, are attributed a strong authority which results in the ignorance of individual circumstances and fates\.

Many companies strive for the opposite of human autonomy, employing more and more subtle techniques for manipulating user behaviour via micro\-targeting, nudging, UX\-design and the like\.

Another example is that of cohesion\. Many of the major scandals of the last years would have been unthinkable without the use of AI\. From echo chamber effects to the use of propaganda bots, or the spread of fake news\.

Currently, AI ethics is failing in many cases\. Ethics lacks a reinforcement mechanism\. Deviations from the various codes of ethics have no consequences\. And in cases where ethics is integrated into institutions, it mainly serves as a marketing strategy\. Furthermore, empirical experiments show that reading ethics guidelines have no significant influence on the decision\-making of software developers\. In practice, AI ethics is often considered as extraneous, as surplus or some kind of ‘add\-on’ to technical concerns, as an unbinding framework that is imposed from institutions ‘outside’ of the technical community\.
### Could Technology and AI make us better humans?

This is a question I ask myself regularly — and I hope you will too\.

A stronger focus on technical details of the various methods and technologies in the field of AI and machine learning is required\. This should ultimately serve to close the gap between ethics and technical discourses\. It is necessary to build tangible bridges between abstract values, technical implementations, and ‘humanness’ as long as these bridges can be reasonably constructed\.


> _Can tools be designed to enhance rather than sacrifice independence, privacy and power? Can we create tools that return choice and control to the employees, stakeholders and consumers?_ 





Imagine what these technologies could look like if we focus on increasing individuals’ cognitive, social and survival skills — providing the ability to not only think for themselves but take informed action and interact effectively with others\.

We recognise that when groups of people come together to solve a problem — they become more than the sum of their parts\. This isn’t a new concept\. Aristotle noted that many unremarkable people often make better collective judgments than great individuals\. This ‘wisdom of the crowd’ is still utilised today from team workshops to the calls on social media of crowdsourcing the ‘hivemind’\.

We know that the future of work is about collaboration and problem\-solving\. Advances in AI could make harnessing the collective wisdom and finding solutions much more accessible\. It could even make us more effective at our jobs and better able to solve social challenges\.

Could we pioneer ways for people around the world to come to common understandings and agreements — to join forces and facilitate the innovation of approaches for tackling wicked problems?

What about tools that help us be more inclusive? Considerate? Empathic?

Australia has a significant opportunity to be not only a leading technology developer and adopter of data\-driven AI systems and technologies — but ethical leadership as well\.

Australia has established, and globally recognised, strengths in some of the key data\-driven capability areas core to AI — including data sharing or federation, trustworthy systems, machine learning, image analytics, natural language processing and automation\.

Supported through the National Innovation and Science Agenda \(NISA\), initiatives such as Platforms for Open Data \(PFOD\) are enabling Australian Government agencies to work with CSIRO’s Data61 to test and validate techniques for allowing trusted access to high\-value, Government datasets, whilst preserving the data’s confidentiality and integrity\.

In order for Australia to take full advantage of the opportunities presented by data\-driven AI, governments, businesses and the community will need to strengthen their levels of awareness, adoption and acceptance of AI’s use, and that will require a deeper level of trust in the integrity of AI\-based systems\.


> _We have a choice — to build inclusive, decentralised, intelligent tools that help humans and aggressively meet social and ethical responsibilities — or to create tools that mirror dystopian consequences\._ 





Is focussing on ethics enough? Perhaps we need to develop a ‘moonshot’ scorecard to assure AI and other technologies directed at ‘humanness’ and the common good\.
### So What Have I learnt?

If my moral compass represents my ethics, and the algorithm represents the Catholic Church, I can see what went wrong\. The church algorithm was constantly trying to push a value set that was developed a thousand years ago and grew based on the search history of countless others\.

It assumed that humans were not inherently good and needed constant correction\. It did not provide transparency of purpose and asked me to trust it when trust had not yet been earned\.

I chose instead to create a process whereby my decisions and choices were driven by a set of clearly defined ethical positions\. I thoroughly reached and adopted these principles as the mantra of my life, and yes, many of those did originate from my religious learning\.

Clearly, though, they are transparent and guided by the people I trust the most\. AI algorithms, it’s your turn now\.

Originally [Published on LinkedIn](https://www.linkedin.com/pulse/machine-learning-hasnt-learnt-enough-ethics-ta%C3%AEss/){:target="_blank"} on October 30, 2020



_[Post](https://medium.com/@TaissQ/machine-learning-hasnt-learnt-enough-about-ethics-3a0ebdb2a452){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
